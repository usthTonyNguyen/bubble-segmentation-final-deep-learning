{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a2473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd15b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration Section ---\n",
    "END_WITH_LOCAL = 'detectron2'\n",
    "\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "print(f\"NOTEBOOK_DIR: {NOTEBOOK_DIR}\")\n",
    "\n",
    "# Simple validation\n",
    "if not (NOTEBOOK_DIR.endswith('/content') or NOTEBOOK_DIR.endswith(END_WITH_LOCAL)):\n",
    "    raise ValueError(f\"Expected to be in .../{END_WITH_LOCAL} or .../content directory, but got: {NOTEBOOK_DIR}\")\n",
    "\n",
    "BASE_DIR = os.path.join(NOTEBOOK_DIR, '..', '..', '..')\n",
    "print(f\"BASE_DIR: {BASE_DIR}\")\n",
    "\n",
    "# Paths to your data and model files\n",
    "JSON_DIR = os.path.join(BASE_DIR, 'data', 'MangaSegmentation/jsons_processed')\n",
    "IMAGE_ROOT_DIR = os.path.join(BASE_DIR, 'data', 'Manga109_released_2023_12_07/images')\n",
    "PRE_TRAINED_MODEL_DIR = os.path.join(BASE_DIR, 'models', 'bubble-detection','detectron2','pre-trained_model')\n",
    "\n",
    "# The category we want to train on\n",
    "TARGET_CATEGORY_ID = 5\n",
    "TARGET_CATEGORY_NAME = \"balloon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Preparation ---\n",
    "\n",
    "def prepare_manga_balloon_data(json_dir, image_root):\n",
    "    \"\"\"\n",
    "    Loads pre-processed JSON files and filters for the target category.\n",
    "    This function is now extremely fast as no conversion is needed.\n",
    "    \"\"\"\n",
    "    dataset_dicts = []\n",
    "    all_images = {}\n",
    "    all_annotations = defaultdict(list)\n",
    "\n",
    "    print(\"Loading and parsing PRE-PROCESSED JSON files...\")\n",
    "    for json_file in os.listdir(json_dir):\n",
    "        if not json_file.endswith('.json'): continue\n",
    "        with open(os.path.join(json_dir, json_file), 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for img_info in data['images']:\n",
    "                all_images[img_info['id']] = img_info\n",
    "            for ann_info in data['annotations']:\n",
    "                all_annotations[ann_info['image_id']].append(ann_info)\n",
    "\n",
    "    print(f\"Loaded data for {len(all_images)} total images.\")\n",
    "    \n",
    "    for img_id, img_info in all_images.items():\n",
    "        record = {}\n",
    "        record[\"file_name\"] = os.path.join(image_root, img_info['file_name'])\n",
    "        record[\"image_id\"] = img_id\n",
    "        record[\"height\"] = img_info['height']\n",
    "        record[\"width\"] = img_info['width']\n",
    "        objs = []\n",
    "        for ann in all_annotations[img_id]:\n",
    "            if ann['category_id'] == TARGET_CATEGORY_ID:\n",
    "                obj = {\n",
    "                    \"bbox\": ann['bbox'],\n",
    "                    \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                    \"segmentation\": ann['segmentation'], \n",
    "                    \"category_id\": 0,\n",
    "                }\n",
    "                objs.append(obj)\n",
    "        if len(objs) > 0:\n",
    "            record[\"annotations\"] = objs\n",
    "            dataset_dicts.append(record)\n",
    "            \n",
    "    print(f\"Finished data preparation. Found {len(dataset_dicts)} images containing '{TARGET_CATEGORY_NAME}'.\")\n",
    "    return dataset_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fac6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Register Datasets with Detectron2  ---\n",
    "\n",
    "# Prepare the data\n",
    "all_data = prepare_manga_balloon_data(JSON_DIR, IMAGE_ROOT_DIR)\n",
    "\n",
    "# --- Group data by manga title ---\n",
    "print(\"\\nGrouping data by manga series for a robust train/val split...\")\n",
    "grouped_data = defaultdict(list)\n",
    "for record in all_data:\n",
    "    # Extract manga name from the file path.\n",
    "    manga_name = os.path.basename(os.path.dirname(record['file_name']))\n",
    "    grouped_data[manga_name].append(record)\n",
    "\n",
    "print(f\"Found {len(grouped_data)} unique manga series.\")\n",
    "\n",
    "# --- Split manga titles, not individual pages ---\n",
    "manga_titles = list(grouped_data.keys())\n",
    "train_titles, val_titles = train_test_split(manga_titles, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Splitting into {len(train_titles)} series for training and {len(val_titles)} for validation.\")\n",
    "\n",
    "# --- Reconstruct train and val sets based on the split titles ---\n",
    "train_data = []\n",
    "for title in train_titles:\n",
    "    train_data.extend(grouped_data[title])\n",
    "\n",
    "val_data = []\n",
    "for title in val_titles:\n",
    "    val_data.extend(grouped_data[title])\n",
    "\n",
    "# Shuffle the datasets to ensure randomness within each set\n",
    "random.Random(42).shuffle(train_data)\n",
    "random.Random(42).shuffle(val_data)\n",
    "\n",
    "print(f\"\\nFinal training set size: {len(train_data)} images\")\n",
    "print(f\"Final validation set size: {len(val_data)} images\")\n",
    "# Verify that no manga series is in both sets\n",
    "assert len(set(train_titles) & set(val_titles)) == 0, \"Data leakage detected! Same manga in train and val.\"\n",
    "print(\"Split verified: No data leakage between train and validation sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff75758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries for the DataFrame\n",
    "train_split_info = [{'manga_title': title, 'dataset_split': 'train'} for title in train_titles]\n",
    "val_split_info = [{'manga_title': title, 'dataset_split': 'validation'} for title in val_titles]\n",
    "\n",
    "# Register the datasets\n",
    "if \"manga_balloon_train\" in DatasetCatalog.list():\n",
    "    DatasetCatalog.remove(\"manga_balloon_train\")\n",
    "if \"manga_balloon_val\" in DatasetCatalog.list():\n",
    "    DatasetCatalog.remove(\"manga_balloon_val\")\n",
    "\n",
    "DatasetCatalog.register(\"manga_balloon_train\", lambda: train_data)\n",
    "DatasetCatalog.register(\"manga_balloon_val\", lambda: val_data)\n",
    "\n",
    "# Set metadata for the datasets\n",
    "MetadataCatalog.get(\"manga_balloon_train\").set(thing_classes=[TARGET_CATEGORY_NAME])\n",
    "MetadataCatalog.get(\"manga_balloon_val\").set(thing_classes=[TARGET_CATEGORY_NAME])\n",
    "\n",
    "balloon_metadata = MetadataCatalog.get(\"manga_balloon_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90afe908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 6. Training ---\n",
    "\n",
    "print(\"\\nConfiguring the model for training...\")\n",
    "cfg = get_cfg()\n",
    "\n",
    "# Load the base configuration from Detectron2's model zoo\n",
    "# Use model_zoo.get_config_file() instead of a local path\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "# Point to the datasets\n",
    "cfg.DATASETS.TRAIN = (\"manga_balloon_train\",)\n",
    "cfg.DATASETS.TEST = (\"manga_balloon_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 8\n",
    "\n",
    "# Load pretrained weights from model zoo\n",
    "# This will automatically download if not cached\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.MODEL.DEVICE = str(device)\n",
    "\n",
    "# --- Training Hyperparameters ---\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1  # Batch size. Adjust based on GPU memory\n",
    "cfg.SOLVER.BASE_LR = 0.00025 # Learning rate\n",
    "cfg.SOLVER.MAX_ITER = 50     # Number of training iterations: 3000, set to 50 for quick test\n",
    "\n",
    "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
    "cfg.SOLVER.WARMUP_ITERS = 300        # Number step \"initial\" with low LR\n",
    "cfg.SOLVER.WARMUP_FACTOR = 1.0 / 300 # Start from LR = BASE_LR * WARMUP_FACTOR\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "\n",
    "# --- Crucial Step: Set the Number of Classes ---\n",
    "# We only have one class (balloon), so we set NUM_CLASSES to 1.\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "\n",
    "# Define the output directory for logs and trained models\n",
    "cfg.OUTPUT_DIR = os.path.join(BASE_DIR, 'models', 'bubble-detection','detectron2','output_balloon_segmentation_v3')\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1970d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf86df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# --- 7. Setup for Inference and Evaluation ---\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\n--- Setting up for testing ---\")\n",
    " \n",
    "final_checkpoint_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "print(f\"Loading final model weights from: {final_checkpoint_path}\")\n",
    "cfg.MODEL.WEIGHTS = final_checkpoint_path\n",
    "\n",
    "# Set a threshold for filtering low-confidence predictions during testing\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Adjust this (0.0 to 1.0) as needed\n",
    "\n",
    "# 2. Create the Predictor\n",
    "predictor = DefaultPredictor(cfg)\n",
    "print(\"Predictor loaded successfully.\")\n",
    "\n",
    "# Get metadata for the validation set\n",
    "val_metadata = MetadataCatalog.get(\"manga_balloon_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# --- 8. Qualitative Testing (Visualization) ---\n",
    "# ==============================================================\n",
    "print(\"\\n--- Starting Qualitative Visualization on Random Validation Samples ---\")\n",
    "\n",
    "# Create a directory to save visualization results\n",
    "# vis_output_dir = \"./balloon_test_visualizations\" #\n",
    "vis_output_dir = os.path.join(BASE_DIR, 'output', 'bubble-detection','detectron2','balloon_test_visualizations')  \n",
    "os.makedirs(vis_output_dir, exist_ok=True)\n",
    "\n",
    "# Number of random samples to visualize\n",
    "num_samples = 20\n",
    "\n",
    "local_rng = random.Random(42)\n",
    "samples = local_rng.sample(val_data, min(num_samples, len(val_data)))\n",
    "\n",
    "for i, d in enumerate(samples):\n",
    "    img_path = d[\"file_name\"]\n",
    "\n",
    "    # Overall path: .../images/MangaName/PageNumber.jpg\n",
    "    dir_path, page_filename = os.path.split(img_path)\n",
    "    _, manga_name = os.path.split(dir_path)\n",
    "    \n",
    "    # \n",
    "    page_name_no_ext = os.path.splitext(page_filename)[0]\n",
    "\n",
    "    print(f\"Processing sample {i+1}/{len(samples)}: Manga='{manga_name}', Page='{page_filename}'\")\n",
    "\n",
    "    # Read image (OpenCV reads as BGR)\n",
    "    im = cv2.imread(img_path)\n",
    "\n",
    "    # Perform Inference\n",
    "    outputs = predictor(im)\n",
    "\n",
    "    # Visualize\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=val_metadata,\n",
    "                   instance_mode=ColorMode.IMAGE_BW\n",
    "    )\n",
    "\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "    # Output: pred_MangaName_PageNum.jpg\n",
    "    save_filename = f\"pred_{manga_name}_{page_name_no_ext}.jpg\"\n",
    "    save_path = os.path.join(vis_output_dir, save_filename)\n",
    "\n",
    "    cv2.imwrite(save_path, out.get_image()[:, :, ::-1])\n",
    "\n",
    "print(f\"Saved {len(samples)} visualization results to '{vis_output_dir}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3ded58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# --- 9. Quantitative Evaluation (COCO Metrics / AP) ---\n",
    "# ==============================================================\n",
    "print(\"\\n--- Starting Quantitative Evaluation on Entire Validation Set ---\")\n",
    "\n",
    "# 1. Define the Evaluator\n",
    "evaluator = COCOEvaluator(\"manga_balloon_val\", output_dir=cfg.OUTPUT_DIR)\n",
    "\n",
    "# 2. Create the Test Dataloader\n",
    "val_loader = build_detection_test_loader(cfg, \"manga_balloon_val\")\n",
    "\n",
    "# 3. Run Inference and Evaluation\n",
    "results = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "\n",
    "print(\"\\n--- Evaluation Results (Average Precision) ---\")\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c33d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir ./output_balloon_segmentation_v3/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
