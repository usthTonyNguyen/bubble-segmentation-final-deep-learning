{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ef700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Required Libraries ---\n",
    "\n",
    "# File and data handling\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# Data processing and visualization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from tqdm.notebook import tqdm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c924c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = os.getcwd()\n",
    "\n",
    "if not NOTEBOOK_DIR.endswith(\"YOLO_Ultralytics\"):\n",
    "    raise ValueError(\"Please set the working directory to 'YOLO_Ultralytics' folder. Currently it is set to: \" + NOTEBOOK_DIR)\n",
    "\n",
    "BASE_DIR = os.path.join(NOTEBOOK_DIR, \"..\", \"..\", \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration Section ---\n",
    "\n",
    "# Paths to your data and model files\n",
    "JSON_DIR = os.path.join(BASE_DIR, 'data', 'MangaSegmentation/jsons_processed') \n",
    "IMAGE_ROOT_DIR = os.path.join(BASE_DIR, 'data', 'Manga109_released_2023_12_07','images')  \n",
    "DATASET_DIR = os.path.join(BASE_DIR, 'data', 'YOLO_data')\n",
    "PROJECT_DIR = os.path.join(BASE_DIR, 'models', 'bubble-detection', 'YOLOv8n_Training_Results')\n",
    "yaml_path = Path(DATASET_DIR) / 'dataset.yaml'\n",
    "\n",
    "# Validate paths\n",
    "print(\"\\nValidating directories...\")\n",
    "for path in [JSON_DIR, IMAGE_ROOT_DIR]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Directory not found: {path}\")\n",
    "    else:\n",
    "        print(f\"Found directory: {path}\")\n",
    "        # List some contents\n",
    "        contents = os.listdir(path)[:5]\n",
    "        print(f\"Sample contents: {contents}\")\n",
    "\n",
    "# Create dataset directories\n",
    "print(\"\\nCreating dataset directories...\")\n",
    "for split in ['train', 'val']:\n",
    "    for subdir in ['images', 'labels']:  \n",
    "        dir_path = os.path.join(DATASET_DIR, f'{subdir}/{split}')\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        print(f\"Created: {dir_path}\")\n",
    "\n",
    "# Set category information directly\n",
    "TARGET_CATEGORY_ID = 5  # Fixed category ID for balloon\n",
    "TARGET_CATEGORY_NAME = \"balloon\"  # Fixed category name\n",
    "\n",
    "print(\"Target Category Configuration:\")\n",
    "print(\"Category ID: {TARGET_CATEGORY_ID}\")\n",
    "print(\"Category Name: {TARGET_CATEGORY_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99da8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Preparation ---\n",
    "\n",
    "print(\"\\n--- 2. Preparing Data from Processed JSONs ---\")\n",
    "\n",
    "def prepare_manga_balloon_data(json_dir, image_root):\n",
    "    \"\"\"\n",
    "    Loads pre-processed JSON files (with polygons), filters for the target \n",
    "    category, and returns a list of image records. This logic is adapted \n",
    "    from your working 'train_v3 copy.ipynb'.\n",
    "    \"\"\"\n",
    "    all_images = {}\n",
    "    all_annotations = defaultdict(list)\n",
    "\n",
    "    print(\"Loading and parsing PRE-PROCESSED JSON files...\")\n",
    "    json_files = [f for f in os.listdir(json_dir) if f.endswith('.json')]\n",
    "    \n",
    "    for json_file in tqdm(json_files, desc=\"Processing JSONs\"):\n",
    "        with open(os.path.join(json_dir, json_file), 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for img_info in data.get('images', []):\n",
    "                all_images[img_info['id']] = img_info\n",
    "            for ann_info in data.get('annotations', []):\n",
    "                all_annotations[ann_info['image_id']].append(ann_info)\n",
    "\n",
    "    print(f\"Loaded data for {len(all_images)} total images.\")\n",
    "\n",
    "    dataset_records = []\n",
    "    for img_id, img_info in all_images.items():\n",
    "        # Create a base record for the image\n",
    "        record = {\n",
    "            \"file_name\": os.path.join(image_root, img_info['file_name']),\n",
    "            \"image_id\": img_id,\n",
    "            \"height\": img_info['height'],\n",
    "            \"width\": img_info['width'],\n",
    "        }\n",
    "        \n",
    "        # Filter for balloon annotations\n",
    "        balloon_annotations = []\n",
    "        for ann in all_annotations.get(img_id, []):\n",
    "            if ann.get('category_id') == TARGET_CATEGORY_ID:\n",
    "                # Ensure segmentation data is present and not empty\n",
    "                if ann.get('segmentation'):\n",
    "                    balloon_annotations.append({\n",
    "                        \"segmentation\": ann['segmentation'],\n",
    "                        \"category_id\": 0,  # All balloons will be class 0\n",
    "                    })\n",
    "        \n",
    "        # Only add images that contain at least one balloon\n",
    "        if balloon_annotations:\n",
    "            record[\"annotations\"] = balloon_annotations\n",
    "            dataset_records.append(record)\n",
    "            \n",
    "    print(f\"Data preparation complete. Found {len(dataset_records)} images containing '{TARGET_CATEGORY_NAME}'.\")\n",
    "    return dataset_records\n",
    "\n",
    "# Run the data preparation\n",
    "all_data = prepare_manga_balloon_data(JSON_DIR, IMAGE_ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108def7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Split and Prepare YOLO Dataset ---\n",
    "\n",
    "# Prepare the data\n",
    "all_data = prepare_manga_balloon_data(JSON_DIR, IMAGE_ROOT_DIR)\n",
    "\n",
    "# --- Group data by manga title ---\n",
    "print(\"\\nGrouping data by manga series for a robust train/val split...\")\n",
    "grouped_data = defaultdict(list)\n",
    "for record in all_data:\n",
    "    manga_name = Path(record['file_name']).parts[-2]\n",
    "    grouped_data[manga_name].append(record)\n",
    "print(f\"Found {len(grouped_data)} unique manga series.\")\n",
    "\n",
    "# Split manga titles to prevent data leakage\n",
    "manga_titles = list(grouped_data.keys())\n",
    "train_titles, val_titles = train_test_split(manga_titles, test_size=0.2, random_state=42)\n",
    "print(f\"Splitting into {len(train_titles)} training series and {len(val_titles)} validation series.\")\n",
    "\n",
    "# Reconstruct train/val lists based on the title split\n",
    "train_data = [record for title in train_titles for record in grouped_data[title]]\n",
    "val_data = [record for title in val_titles for record in grouped_data[title]]\n",
    "random.Random(42).shuffle(train_data)\n",
    "random.Random(42).shuffle(val_data)\n",
    "print(f\"Final training set size: {len(train_data)} images\")\n",
    "print(f\"Final validation set size: {len(val_data)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a34a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset_split_segmentation(data_split, split_type):\n",
    "    \"\"\"\n",
    "    Processes a dataset to create a YOLO INSTANCE SEGMENTATION dataset.\n",
    "    This function will write normalized polygon coordinates to a .txt file.\n",
    "    \"\"\"\n",
    "    total_annotations = 0\n",
    "    \n",
    "    for record in tqdm(data_split, desc=f\"Processing {split_type} split\"):\n",
    "        original_img_path = record['file_name']\n",
    "        img_height = record['height']\n",
    "        img_width = record['width']\n",
    "        \n",
    "        # Check if image exists\n",
    "        if not os.path.exists(original_img_path):\n",
    "            print(f\"Warning: Image not found at {original_img_path}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Create unique identifiers for images to avoid duplicate names\n",
    "        manga_title = Path(original_img_path).parts[-2]\n",
    "        img_stem = Path(original_img_path).stem\n",
    "        img_identifier = f\"{manga_title}_{img_stem}\"\n",
    "        \n",
    "        # 1. Copy images to folder train/val\n",
    "        dest_img_path = os.path.join(DATASET_DIR, f'images/{split_type}', f\"{img_identifier}.jpg\")\n",
    "        shutil.copy2(original_img_path, dest_img_path)\n",
    "        \n",
    "        # 2. Create corresponding .txt label file\n",
    "        label_path = os.path.join(DATASET_DIR, f'labels/{split_type}', f\"{img_identifier}.txt\")\n",
    "        \n",
    "        # 3. Write normalized polygon coordinates to label file\n",
    "        with open(label_path, 'w') as f:\n",
    "            for ann in record.get('annotations', []):\n",
    "                # Each 'ann' corresponds to a balloon (an object)\n",
    "                segmentation = ann.get('segmentation')\n",
    "                if not segmentation:\n",
    "                    continue\n",
    "                \n",
    "                # Each object can have multiple polygons (complex cases)\n",
    "                for poly in segmentation:\n",
    "                    # Normalize the coordinates of the polygon\n",
    "                    # poly is a list number [x1, y1, x2, y2, ...]\n",
    "                    normalized_poly = []\n",
    "                    for i in range(0, len(poly), 2):\n",
    "                        x = poly[i] / img_width\n",
    "                        y = poly[i+1] / img_height\n",
    "                        normalized_poly.extend([x, y])\n",
    "                    \n",
    "                    # Write to file in format: class_id x1 y1 x2 y2 ...\n",
    "                    # Class ID is always 0 because we only have 1 class \"balloon\"\n",
    "                    if normalized_poly:\n",
    "                        f.write(f\"0 {' '.join(map(str, normalized_poly))}\\n\")\n",
    "                        total_annotations += 1\n",
    "    \n",
    "    return len(data_split), total_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f35e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execute data conversion with debugged function ---\n",
    "print(\"Processing training split...\")\n",
    "train_images_count, train_annotations_count = process_dataset_split_segmentation(train_data, 'train')\n",
    "print(\"Processing validation split...\")\n",
    "val_images_count, val_annotations_count = process_dataset_split_segmentation(val_data, 'val')\n",
    "\n",
    "# --- Check and verify ---\n",
    "print(\"Dataset created successfully:\")\n",
    "print(f\"Training images: {train_images_count}\")\n",
    "print(f\"Training annotations (polygons): {train_annotations_count}\")\n",
    "print(f\"Validation images: {val_images_count}\")\n",
    "print(f\"Validation annotations (polygons): {val_annotations_count}\")\n",
    "\n",
    "final_train_images = len(os.listdir(os.path.join(DATASET_DIR, 'images/train')))\n",
    "final_val_images = len(os.listdir(os.path.join(DATASET_DIR, 'images/val')))\n",
    "\n",
    "print(\"Final verification from disk:\")\n",
    "print(f\"Total training images in folder: {final_train_images}\")\n",
    "print(f\"Total validation images in folder: {final_val_images}\")\n",
    "\n",
    "if final_train_images == len(train_data) and final_val_images == len(val_data):\n",
    "    print(\"\\nVerification successful: All images were copied correctly.\")\n",
    "else:\n",
    "    print(\"\\nVerification WARNING: Mismatch in image counts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create YAML Configuration\n",
    "print(\"\\n--- 4. Creating dataset.yaml Configuration File ---\")\n",
    "\n",
    "dataset_config = {\n",
    "    'path': os.path.abspath(DATASET_DIR),\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'names': {\n",
    "        0: TARGET_CATEGORY_NAME\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(dataset_config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"YAML configuration saved to: {yaml_path}\")\n",
    "print(\"\\nYAML Content:\")\n",
    "print(yaml.dump(dataset_config))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
